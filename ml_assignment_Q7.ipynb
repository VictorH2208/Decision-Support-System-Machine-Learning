{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-ZYhG2zn3qf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcqEP3fGkec9",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806f5506-7bda-4775-e84e-6465c3a88bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Please add other necessary imports here\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nq7O9NKnnorw"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "from pathlib import Path\n",
        "filename = wget.download(\"https://github.com/MIE451-1513-2023/course-datasets/raw/main/20_newsgroups.zip\", \"20_newsgroups.zip\")\n",
        "_ = wget.download(\"https://github.com/MIE451-1513-2023/course-datasets/raw/main/training_files_Q7.txt\", \"training_files_Q7.txt\")\n",
        "_ = wget.download(\"https://github.com/MIE451-1513-2023/course-datasets/raw/main/testing_files_Q7.txt\", \"testing_files_Q7.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwVs1bGK64FB"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip 20_newsgroups.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgyLW2Lp69RD"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"20_newsgroups\"\n",
        "ALL_FILES = [pth for pth in Path(DATA_DIR).glob(\"**/*\") if pth.is_file() and not pth.name.startswith(\".\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "432hrnVOkedA"
      },
      "source": [
        "# Q7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSihMe6ekedB"
      },
      "source": [
        "## Q7(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwX8PxjCkedD"
      },
      "source": [
        "use the following code cell to implement your feature encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aknEVgx0kedD"
      },
      "outputs": [],
      "source": [
        "def data_q7(file_list, num_words=1000):\n",
        "    X, y = None, None\n",
        "\n",
        "    tokenizer = RegexpTokenizer(r\"\\b[a-zA-Z]+\\b\")\n",
        "    stemmer = PorterStemmer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def clean_file_text(text):\n",
        "        new_text = re.sub(\"Newsgroups:.*?\\n\", \"\", text)\n",
        "        new_text = re.sub(\"Xref:.*?\\n\", \"\", new_text)\n",
        "        new_text = re.sub(\"Path:.*?\\n\", \"\", new_text)\n",
        "        new_text = re.sub(\"Date:.*?\\n\", \"\", new_text)\n",
        "        new_text = re.sub(\"Followup-To:.*?\\n\", \"\", new_text)\n",
        "        new_text = re.sub(\"Lines:.*?\\n\", \"\", new_text)\n",
        "        new_text = re.sub(\"Reply-To:.*?\\n\", \"\", new_text)\n",
        "        new_text = re.sub(\"Message-ID:.*?\\n\", \"\", new_text)\n",
        "        new_text = re.sub(\"From:.*?\\n\", \"\", new_text)\n",
        "        new_text = re.sub(\"NNTP-Posting-Host:.*?\\n\", \"\", new_text)\n",
        "        return new_text\n",
        "\n",
        "    def get_topic_name(file_path):\n",
        "        return file_path.parent.name\n",
        "\n",
        "    def get_target(topic_name):\n",
        "        topics = [\"talk.politics.mideast\", \"rec.autos\", \"comp.sys.mac.hardware\", \"alt.atheism\", \"rec.sport.baseball\",\n",
        "        \"comp.os.ms-windows.misc\", \"rec.sport.hockey\", \"sci.crypt\", \"sci.med\", \"talk.politics.misc\",\n",
        "        \"rec.motorcycles\", \"comp.windows.x\", \"comp.graphics\", \"comp.sys.ibm.pc.hardware\", \"sci.electronics\",\n",
        "        \"talk.politics.guns\", \"sci.space\", \"soc.religion.christian\", \"misc.forsale\", \"talk.religion.misc\"]\n",
        "        return topics.index(topic_name)\n",
        "\n",
        "    def stemmed_tokenizer(doc):\n",
        "        tokens = tokenizer.tokenize(doc)\n",
        "        tokens = [token.lower() for token in tokens]  # Convert to lowercase\n",
        "        tokens = [token for token in tokens if token not in stop_words]  # Remove stopwords\n",
        "        stemmed = [stemmer.stem(token) for token in tokens]  # Stemming\n",
        "        return stemmed\n",
        "\n",
        "    def load_file_content(file_path):\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "            content = clean_file_text(file.read())\n",
        "            return content\n",
        "\n",
        "    y = [get_target(get_topic_name(file_path)) for file_path in ALL_FILES]\n",
        "    documents = [load_file_content(file_path) for file_path in ALL_FILES]\n",
        "\n",
        "    # vectorizer = CountVectorizer(max_features=20000, tokenizer=stemmed_tokenizer) -> not good as tfidf\n",
        "    vectorizer = TfidfVectorizer(max_features=8000, tokenizer=stemmed_tokenizer)\n",
        "    X_prime = vectorizer.fit_transform(documents)\n",
        "    X = pd.DataFrame(X_prime.toarray(), index=[str(f) for f in ALL_FILES], columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "    print(\"finish encoding\")\n",
        "    assert isinstance(X, pd.DataFrame) and isinstance(y, list), \"incorrect return types\"\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNRE4K4gkedE"
      },
      "source": [
        "## Q7(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzXn77E0kedE"
      },
      "source": [
        "Use the following code cell to implement your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gY3zH_yfkedE"
      },
      "outputs": [],
      "source": [
        "def build_model_q7():\n",
        "\n",
        "    # mnnb = MultinomialNB(alpha=0.01,) -> not good as logistic regression\n",
        "    # mlp = MLPClassifier(hidden_layer_sizes=(256, 128), max_iter=10, random_state=42, alpha=0.01,\n",
        "    #     solver='adam', verbose=1, learning_rate='adaptive', activation='relu', early_stopping=False)\n",
        "    MODELQ7 = LogisticRegression(C=10, max_iter=500, class_weight='balanced', multi_class='ovr', n_jobs=-1)\n",
        "    return MODELQ7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWKu6i31kedF"
      },
      "source": [
        "Code for evaluating p at k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4o8CXDJkedF"
      },
      "outputs": [],
      "source": [
        "def calculate_average_precision_at_k(model_q7, data_func, all_files, training_files, testing_files, k=None):\n",
        "\n",
        "    training_files = [str(f) for f in open(training_files, mode='r').read().splitlines()]\n",
        "    testing_files = [str(f) for f in open(testing_files, mode='r').read().splitlines()]\n",
        "    if k is None:\n",
        "        k = len(testing_files)\n",
        "\n",
        "    X, y = data_func(all_files)\n",
        "    X[\"gt\"] = y\n",
        "    training = X.loc[training_files]\n",
        "    X_train = training.loc[:, training.columns!=\"gt\"]\n",
        "    y_train = training[\"gt\"].values\n",
        "\n",
        "    testing = X.loc[testing_files]\n",
        "    X_test = testing.loc[:, testing.columns!=\"gt\"]\n",
        "    y_test = testing[\"gt\"].values\n",
        "\n",
        "    model_q7.fit(X_train, y_train)\n",
        "    y_pred = model_q7.predict(X_test)\n",
        "    y_pred_prob = model_q7.predict_proba(X_test)\n",
        "    confidences = np.max(y_pred_prob, axis=1)\n",
        "\n",
        "    p_at_k = []\n",
        "    rel_at_k = []\n",
        "    confidence_order = np.argsort(confidences)\n",
        "    for i in range(1, k+1):\n",
        "        top_confidence = confidence_order[-i:]\n",
        "        pred_top_i = y_pred[top_confidence]\n",
        "        gt_top_i = np.array(y_test)[top_confidence]\n",
        "        p_at_i = np.sum(pred_top_i == gt_top_i) / i\n",
        "        rel_at_i = (pred_top_i[0] == gt_top_i[0])\n",
        "        p_at_k.append(p_at_i)\n",
        "        rel_at_k.append(rel_at_i)\n",
        "    print(f\"average precision at {k} is {np.dot(p_at_k, rel_at_k) / k}\")\n",
        "\n",
        "    # val = X.loc[X.index.difference(set(training_files)|set(testing_files)), :]\n",
        "    # X_val = val.loc[ :, val.columns!=\"gt\"]\n",
        "    # y_val = val[\"gt\"].values\n",
        "\n",
        "    # y_pred = model_q7.predict(X_val)\n",
        "    # y_pred_prob = model_q7.predict_proba(X_val)\n",
        "    # confidences = np.max(y_pred_prob, axis=1)\n",
        "\n",
        "    # p_at_k = []\n",
        "    # rel_at_k = []\n",
        "    # confidence_order = np.argsort(confidences)\n",
        "    # for i in range(1, len(y_val)+1):\n",
        "    #     top_confidence = confidence_order[-i:]\n",
        "    #     pred_top_i = y_pred[top_confidence]\n",
        "    #     gt_top_i = np.array(y_val)[top_confidence]\n",
        "    #     p_at_i = np.sum(pred_top_i == gt_top_i) / i\n",
        "    #     rel_at_i = (pred_top_i[0] == gt_top_i[0])\n",
        "    #     p_at_k.append(p_at_i)\n",
        "    #     rel_at_k.append(rel_at_i)\n",
        "    # print(f\"average precision at {len(y_val)} is {np.dot(p_at_k, rel_at_k) / len(y_val)}\")\n",
        "\n",
        "    return np.dot(p_at_k, rel_at_k) / k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmicMF0ykedG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf0f9d4b-df6c-4273-e519-f01abb7c5d35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish encoding\n",
            "average precision at 4000 is 0.83744161797728\n"
          ]
        }
      ],
      "source": [
        "m = calculate_average_precision_at_k(build_model_q7(), data_q7, ALL_FILES, \"training_files_Q7.txt\", \"testing_files_Q7.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8y4vOO5kedH"
      },
      "source": [
        "# Q7(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Set and Feature Encoding:**\n",
        "\n",
        "The chosen feature set in this scenario is based on TF-IDF encoding. This encoding helps capture the importance of terms in distinguishing different topics within the text. The words in the document were first tokenized using a RegesTokenizer then covert to lower case. After, stop words are removed from the list of tokens and each tokens are stemmed.\n",
        "\n",
        "**Classifier:**\n",
        "\n",
        "The chosen classifier is Logistic Regression. Logistic Regression is a well-established classification algorithm that works well for text classification tasks. It can handle high-dimensional feature spaces, making it a good choice when using TF-IDF encoding.\n",
        "\n",
        "TF-IDF encoding was chosen because it is effective for text classification tasks. It takes into account both term frequency and inverse document frequency, which helps in capturing the importance of words in distinguishing between different topics. It also works well with text data have a large number of features.\n",
        "\n",
        "Logistic Regression was chosen because it is a simple but effective classification model. It outperforms the other methods I have tried.\n",
        "\n",
        "Final: 0.838 with 8000 num of word"
      ],
      "metadata": {
        "id": "-pOSM-PDYTn3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXORTLuikedH"
      },
      "source": [
        "**multiNB** \\\n",
        "2000 T: 0.75316 & 0.750048 | C: 0.684028 \\\n",
        "4000 T: 0.800236 & 0.794596 | C: 0.727337 & 0.721242 \\\n",
        "10000 T: 0.836234 & 0.831411 | C: 0.767681 & 0.760828\\\n",
        "20000 T: 0.849466 & 0.845272 | C: 0.779938 & 0.774953\n",
        "\n",
        "\n",
        "**LR**  \n",
        "4000 T: 0.814094 & 0.810094 \\\n",
        "8000 T: 0.838160 & 0.836946 \\\n",
        "10000 T: 0.844272 & 0.842257\\\n",
        "\n",
        "**MLP**\\\n",
        "4000 T: 0.802547 & 0.800840 \\\n",
        "10000 T: 0.834676 & 0.832038 \\\n",
        "20000 T: 0.836802 & 0.836633"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}